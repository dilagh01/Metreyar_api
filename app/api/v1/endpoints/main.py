# main.py
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import pandas as pd
import io
import os
import traceback
from datetime import datetime
import uvicorn
import re
from difflib import get_close_matches

app = FastAPI(
    title="Metreyar API - Ù…Ù‚Ø§ÛŒØ³Ù‡ ØµÙˆØ±Øª ÙˆØ¶Ø¹ÛŒØª (Ù‡ÙˆØ´Ù…Ù†Ø¯)",
    version="1.0.0",
    description="Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ùˆ ÙØ§ÛŒÙ„ ØµÙˆØ±Øª ÙˆØ¶Ø¹ÛŒØª Ø¹Ù…Ø±Ø§Ù†ÛŒ â€” ØªØ´Ø®ÛŒØµ ÙØ§Ø²ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ØŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§ØªÙˆÙ…Ø§ØªÛŒÚ© Ù…Ø¨Ù„Øº"
)

# CORS (Ø¨Ø±Ø§ÛŒ ÙØ±Ø§Ù†Øª)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ----------
MAX_FILE_BYTES = 30 * 1024 * 1024  # 30 MB
# --------------------------------

def _normalize_col_name(col: str) -> str:
    s = str(col)
    s = s.replace("â€Œ", "")  # Ù†ÛŒÙ… ÙØ§ØµÙ„Ù‡
    s = s.replace("_", " ")
    s = re.sub(r"[^\w\s\u0600-\u06FF]", " ", s)  # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø¹Ø¬ÛŒØ¨ (Ø­ÙØ¸ Ø­Ø±ÙˆÙ ÙØ§Ø±Ø³ÛŒ)
    s = s.strip().lower()
    s = re.sub(r"\s+", " ", s)
    return s

def _normalize_text_for_key(s: str) -> str:
    if pd.isna(s):
        return ""
    t = str(s)
    t = t.replace("â€Œ", "")  # Ù†ÛŒÙ… ÙØ§ØµÙ„Ù‡
    t = t.lower().strip()
    # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ ØºÛŒØ± Ø­Ø±Ù/ÙØ§ØµÙ„Ù‡ (Ø§Ø¹Ø¯Ø§Ø¯ Ø±Ø§ Ù†Ú¯Ù‡ Ù†Ø¯Ø§Ø±ÛŒÙ… ÛŒØ§ Ú©Ù†Ø§Ø± Ø¨Ú¯Ø°Ø§Ø±ÛŒÙ…)
    t = re.sub(r"[^\w\u0600-\u06FF\s]", " ", t)
    t = re.sub(r"\s+", " ", t).strip()
    return t

def _to_number_series(ser: pd.Series) -> pd.Series:
    """ØªØ¨Ø¯ÛŒÙ„ Ø³ØªÙˆÙ† Ø´Ø§Ù…Ù„ Ø¹Ø¯Ø¯ (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§ ÙˆÛŒØ±Ú¯ÙˆÙ„/Ú©Ø§Ù…Ø§ÛŒ Ù‡Ø²Ø§Ø± Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡) Ø¨Ù‡ float/int"""
    return pd.to_numeric(
        ser.astype(str)
           .str.replace(r"[,\s]", "", regex=True)
           .str.replace("âˆ’", "-", regex=False)
           .replace(["", "nan", "None"], "0"),
        errors="coerce"
    ).fillna(0)

def _read_file_to_df(file: UploadFile) -> pd.DataFrame:
    filename = file.filename or ""
    ext = filename.lower().split(".")[-1] if "." in filename else ""
    contents = file.file.read()
    if not contents or len(contents) == 0:
        raise HTTPException(status_code=400, detail=f"ÙØ§ÛŒÙ„ {filename} Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
    if len(contents) > MAX_FILE_BYTES:
        raise HTTPException(status_code=400, detail=f"Ø­Ø¬Ù… ÙØ§ÛŒÙ„ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø§Ø³Øª ({MAX_FILE_BYTES} Ø¨Ø§ÛŒØª).")

    try:
        if ext in ("csv",):
            df = pd.read_csv(io.BytesIO(contents), encoding="utf-8", engine="python")
        elif ext in ("xlsx", "xlsm", "xls"):
            if ext in ("xlsx", "xlsm"):
                # openpyxl Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¯Ø± requirements Ù†ØµØ¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯
                df = pd.read_excel(io.BytesIO(contents), engine="openpyxl")
            else:  # ext == 'xls'
                try:
                    df = pd.read_excel(io.BytesIO(contents), engine="xlrd")
                except Exception:
                    raise HTTPException(
                        status_code=400,
                        detail="ÙØ§ÛŒÙ„ .xls Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ 'xlrd' Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ù„Ø·ÙØ§Ù‹ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ .xlsx ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒØ¯."
                    )
        else:
            try:
                df = pd.read_excel(io.BytesIO(contents))
            except Exception:
                raise HTTPException(status_code=400, detail=f"ÙØ±Ù…Øª ÙØ§ÛŒÙ„ {filename} Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ {filename}: {str(e)}")

    if df is None or df.empty:
        raise HTTPException(status_code=400, detail=f"ÙØ§ÛŒÙ„ {filename} Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù†Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ø³Ø§Ø®ØªØ§Ø±Ø´ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª.")
    df.columns = [str(c).strip() for c in df.columns]
    return df

def detect_columns_smart(df: pd.DataFrame) -> dict:
    """
    ØªØ´Ø®ÛŒØµ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§:
      - description  : Ø´Ø±Ø­/Ø´Ø±Ø­ Ú©Ø§Ø±/Ø¹Ù†ÙˆØ§Ù†/Ø¢ÛŒØªÙ…
      - amount       : Ù…Ø¨Ù„Øº / Ø¬Ù…Ø¹ / total / price
      - qty          : Ù…Ù‚Ø¯Ø§Ø± / ØªØ¹Ø¯Ø§Ø¯ / qty
      - unit         : ÙÛŒ / Ù†Ø±Ø® / unit price
    Ø§Ú¯Ø± amount Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ Ø§Ù…Ø§ qty Ùˆ unit_price Ù‡Ø³Øª: Ù…Ø¨Ù„Øº Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
    """
    col_map = {"description": None, "amount": None, "qty": None, "unit": None}
    normalized = {_normalize_col_name(c): c for c in df.columns}

    patterns = {
        "description": ["Ø´Ø±Ø­", "Ø¹Ù†ÙˆØ§Ù†", "Ø¢ÛŒØªÙ…", "Ø´Ø±Ø­ Ú©Ø§Ø±", "subject", "description", "item", "work", "Ø´Ø±Ø­_Ø¹Ù…Ù„ÛŒØ§Øª"],
        "amount": ["Ù…Ø¨Ù„Øº", "Ø¬Ù…Ø¹", "total", "amount", "price", "sum", "Ù…Ø¨Ù„ØºÚ©Ù„", "Ù‚ÛŒÙ…Øª", "Ù…Ø¨Ù„Øº_Ú©Ù„"],
        "qty": ["Ù…Ù‚Ø¯Ø§Ø±", "ØªØ¹Ø¯Ø§Ø¯", "qty", "quantity", "Ø­Ø¬Ù…", "Ù…Ù‚Ø¯Ø§Ø±_Ú©Ø§Ø±"],
        "unit": ["ÙÛŒ", "Ù†Ø±Ø®", "unitprice", "unit price", "rate", "priceunit", "Ù‚ÛŒÙ…Øª_ÙˆØ§Ø­Ø¯"]
    }

    # Ù…Ø±Ø­Ù„Ù‡ Û±: ØªØ·Ø§Ø¨Ù‚ Ù…Ø³ØªÙ‚ÛŒÙ… Ø±ÙˆÛŒ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡
    for norm_name, orig in normalized.items():
        for key, pats in patterns.items():
            if any(p in norm_name for p in pats):
                if col_map[key] is None:
                    col_map[key] = orig

    # Ù…Ø±Ø­Ù„Ù‡ Û²: fuzzy match Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ù†Ø²Ø¯ÛŒÚ©
    names = list(normalized.keys())
    for key, pats in patterns.items():
        if col_map[key] is None:
            for p in pats:
                matches = get_close_matches(p, names, n=1, cutoff=0.6)
                if matches:
                    col_map[key] = normalized[matches[0]]
                    break

    # Ù…Ø±Ø­Ù„Ù‡ Û³: fallback Ø¨Ø±Ø§ÛŒ Ø´Ø±Ø­ (Ø§ÙˆÙ„ÛŒÙ† Ø³ØªÙˆÙ† Ø¨Ø§ Ù…Ù‚Ø¯Ø§Ø± ØºÛŒØ± Ø¹Ø¯Ø¯ÛŒ)
    if not col_map["description"]:
        for c in df.columns:
            sample = df[c].astype(str).head(10).str.strip()
            non_numeric_count = sample.apply(lambda x: bool(re.search(r"[^\d\.\,\-]", x))).sum()
            if non_numeric_count >= 1:
                col_map["description"] = c
                break

    if not col_map["description"]:
        raise HTTPException(status_code=400, detail=f"Ø³ØªÙˆÙ† Ø´Ø±Ø­/Ø¹Ù†ÙˆØ§Ù† Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø³ØªÙˆÙ†â€ŒÙ‡Ø§: {list(df.columns)}")

    # Ù…Ø±Ø­Ù„Ù‡ Û´: Ø§Ú¯Ø± amount Ù†Ø¨ÙˆØ¯ ÙˆÙ„ÛŒ qty Ùˆ unit ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´Øª â†’ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ù†
    if not col_map["amount"]:
        if col_map["qty"] and col_map["unit"]:
            df["__computed_amount__"] = _to_number_series(df[col_map["qty"]]) * _to_number_series(df[col_map["unit"]])
            col_map["amount"] = "__computed_amount__"
        else:
            # Ø§Ú¯Ø± Ø§ØµÙ„Ø§Ù‹ Ù‚Ø§Ø¨Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø¨ÙˆØ¯ØŒ Ù…Ù‚Ø¯Ø§Ø± ØµÙØ± Ø¨Ø²Ø§Ø± (ØªØ§ Ø®Ø·Ø§ Ù†Ø¯Ù‡ÛŒÙ… ÙˆÙ„ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø®Ø§Ù„ÛŒ Ù…Ù†Ø·Ù‚ÛŒ Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯)
            df["__computed_amount__"] = 0
            col_map["amount"] = "__computed_amount__"

    return col_map

def build_merge_key_column(df: pd.DataFrame, desc_col: str, new_col_name: str = "__merge_key__") -> pd.Series:
    """Ø§ÛŒØ¬Ø§Ø¯ Ø³ØªÙˆÙ† Ú©Ù„ÛŒØ¯ Ø§Ø¯ØºØ§Ù… Ø¨Ø± Ù¾Ø§ÛŒÙ‡ Ø´Ø±Ø­ (Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ)"""
    keys = df[desc_col].astype(str).apply(_normalize_text_for_key)
    keys = keys.fillna("").astype(str)
    # Ø§Ú¯Ø± Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯ØŒ Ù…Ù‚Ø¯Ø§Ø± ÛŒÚ©ØªØ§ Ø¨Ø±Ø§Ø´ Ø¨Ø³Ø§Ø²
    empty_mask = keys.str.strip() == ""
    if empty_mask.any():
        # Ø¨Ø±Ø§ÛŒ ÛŒÚ©ØªØ§ÛŒÛŒ Ø§Ø² Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        keys.loc[empty_mask] = keys.loc[empty_mask].index.map(lambda i: f"__empty__{i}")
    df[new_col_name] = keys
    return df[new_col_name]

@app.post("/api/v1/compare-sooratvaziat/")
async def compare_sooratvaziat(
    previous_file: UploadFile = File(..., description="ØµÙˆØ±Øª ÙˆØ¶Ø¹ÛŒØª Ø¯ÙˆØ±Ù‡ Ù‚Ø¨Ù„"),
    current_file: UploadFile = File(..., description="ØµÙˆØ±Øª ÙˆØ¶Ø¹ÛŒØª Ø¯ÙˆØ±Ù‡ Ø¬Ø¯ÛŒØ¯")
):
    try:
        # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        df_prev = _read_file_to_df(previous_file)
        df_curr = _read_file_to_df(current_file)

        # ØªØ´Ø®ÛŒØµ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨ØµÙˆØ±Øª Ù‡ÙˆØ´Ù…Ù†Ø¯
        prev_map = detect_columns_smart(df_prev)
        curr_map = detect_columns_smart(df_curr)

        prev_desc = prev_map["description"]
        prev_amount = prev_map["amount"]
        curr_desc = curr_map["description"]
        curr_amount = curr_map["amount"]

        # ØªØ¨Ø¯ÛŒÙ„ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ø¨Ù„Øº Ø¨Ù‡ Ø¹Ø¯Ø¯
        df_prev[prev_amount] = _to_number_series(df_prev[prev_amount])
        df_curr[curr_amount] = _to_number_series(df_curr[curr_amount])

        # Ù…Ø¬Ù…ÙˆØ¹â€ŒÙ‡Ø§
        total_prev = float(df_prev[prev_amount].sum())
        total_curr = float(df_curr[curr_amount].sum())
        diff = total_curr - total_prev
        percent = round((diff / total_prev * 100), 2) if total_prev != 0 else None

        # Ø³Ø§Ø®Øª Ú©Ù„ÛŒØ¯ Ø§Ø¯ØºØ§Ù… Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡
        build_merge_key_column(df_prev, prev_desc, "__key_prev__")
        build_merge_key_column(df_curr, curr_desc, "__key_curr__")

        # Ø§Ø¯ØºØ§Ù… Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡
        merged = pd.merge(
            df_prev[[prev_desc, prev_amount, "__key_prev__"]],
            df_curr[[curr_desc, curr_amount, "__key_curr__"]],
            how="outer",
            left_on="__key_prev__",
            right_on="__key_curr__",
            suffixes=("_prev", "_curr")
        ).fillna(0)

        # Ú©Ø´Ù Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø³ØªÙˆÙ† Ù…Ø¨Ù„Øº Ø¯Ø± Ø¬Ø¯ÙˆÙ„ merged
        prev_amount_col = prev_amount + "_prev" if (prev_amount + "_prev") in merged.columns else prev_amount
        curr_amount_col = curr_amount + "_curr" if (curr_amount + "_curr") in merged.columns else curr_amount

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªÙØ§ÙˆØª Ùˆ ÙˆØ¶Ø¹ÛŒØª
        merged["ØªÙØ§ÙˆØª"] = merged[curr_amount_col].astype(float) - merged[prev_amount_col].astype(float)
        merged["ÙˆØ¶Ø¹ÛŒØª"] = merged["ØªÙØ§ÙˆØª"].apply(lambda x: "Ø§ÙØ²Ø§ÛŒØ´" if x > 0 else ("Ú©Ø§Ù‡Ø´" if x < 0 else "Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±"))

        # Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø±Ø­ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ (ØªØ±Ø¬ÛŒØ­ Ø´Ø±Ø­ Ø¯ÙˆØ±Ù‡ Ø¬Ø¯ÛŒØ¯)
        if curr_desc in merged.columns:
            merged["Ø´Ø±Ø­_Ù†Ù‡Ø§ÛŒÛŒ"] = merged[curr_desc].replace({0: ""}).astype(str)
        elif prev_desc in merged.columns:
            merged["Ø´Ø±Ø­_Ù†Ù‡Ø§ÛŒÛŒ"] = merged[prev_desc].replace({0: ""}).astype(str)
        else:
            merged["Ø´Ø±Ø­_Ù†Ù‡Ø§ÛŒÛŒ"] = merged.get("__key_prev__", merged.get("__key_curr__", "")).astype(str)

        # Ù†Ù…Ø§ÛŒØ´ Ù…Ø±ØªØ¨â€ŒØ´Ø¯Ù‡
        merged_display = merged[["Ø´Ø±Ø­_Ù†Ù‡Ø§ÛŒÛŒ", prev_amount_col, curr_amount_col, "ØªÙØ§ÙˆØª", "ÙˆØ¶Ø¹ÛŒØª"]].copy()
        merged_display = merged_display.rename(columns={
            "Ø´Ø±Ø­_Ù†Ù‡Ø§ÛŒÛŒ": "Ø´Ø±Ø­ Ú©Ø§Ø±",
            prev_amount_col: "Ù…Ø¨Ù„Øº Ù‚Ø¨Ù„ÛŒ",
            curr_amount_col: "Ù…Ø¨Ù„Øº Ø¬Ø¯ÛŒØ¯"
        })

        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡/Ø­Ø°Ù
        prev_keys = set(df_prev["__key_prev__"].astype(str).unique())
        curr_keys = set(df_curr["__key_curr__"].astype(str).unique())
        added_keys = sorted(list(curr_keys - prev_keys))
        removed_keys = sorted(list(prev_keys - curr_keys))

        added = []
        removed = []
        for k in added_keys[:50]:
            row = df_curr[df_curr["__key_curr__"] == k]
            if not row.empty:
                added.append({
                    "key": k,
                    "title": str(row[curr_desc].astype(str).iloc[0]),
                    "amount": float(_to_number_series(row[curr_amount]).iloc[0])
                })
        for k in removed_keys[:50]:
            row = df_prev[df_prev["__key_prev__"] == k]
            if not row.empty:
                removed.append({
                    "key": k,
                    "title": str(row[prev_desc].astype(str).iloc[0]),
                    "amount": float(_to_number_series(row[prev_amount]).iloc[0])
                })

        result = {
            "message": "success",
            "summary": {
                "previous_sum": total_prev,
                "current_sum": total_curr,
                "difference": diff,
                "progress_percent": percent
            },
            "items_compared": int(len(merged_display)),
            "added_count": len(added_keys),
            "removed_count": len(removed_keys),
            "added_samples": added,
            "removed_samples": removed,
            "data": merged_display.fillna("").to_dict(orient="records")
        }

        return JSONResponse(content=result, status_code=200)

    except HTTPException:
        raise
    except Exception as e:
        # Ù„Ø§Ú¯ Ú©Ø§Ù…Ù„ Ø®Ø·Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø± deploy logs
        print("ðŸ”¥ SERVER ERROR:")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø§ÛŒ Ø³Ø±ÙˆØ±: {str(e)}")

@app.get("/api/v1/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "version": "1.0.0"
    }

@app.get("/")
async def root():
    return {"message": "Metreyar API Service - compare-sooratvaziat", "compare": "/api/v1/compare-sooratvaziat/"}

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run("main:app", host="0.0.0.0", port=port, workers=1)
